---
layout: page
title: Parallelization 
reading: "<a href='https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf'>parallel</a>, <a href='http://cran.r-project.org/web/packages/doMC/vignettes/gettingstartedMC.pdf'>doMC and foreach</a>"
notes: "<a href='https://stat.duke.edu/~cr173/Sta523_Fa14/hw/hw5.html'>HW5</a>"
output: 
    ioslides_presentation:
        widescreen: true
        smaller: false
slides: true
---

```{r echo=FALSE}
suppressMessages(library(parallel))
suppressMessages(library(doMC))
```

# parallel

## parallel

Part of the base packages in R 

* tools for the forking of R processes (some functions do not work on Windows)

* Core functions:
    
    * `detectCores`

    * `pvec`

    * `mclapply`

    * `mcparallel` & `mccollect`


## detectCores

Surprisingly, detects the number of cores of the current system.

```{r}
detectCores()
```

## pvec {.smaller}

Parallelization of a vectorized function call

```{r}
system.time(pvec(1:1e7, sqrt, mc.cores = 1))
system.time(pvec(1:1e7, sqrt, mc.cores = 4))
system.time(pvec(1:1e7, sqrt, mc.cores = 8))
```


##
```{r eval=FALSE}
sapply(c(1,2,4,8,16,24), 
       function(x) 
       {
            sapply(6:9, 
                   function(y)  
                        system.time(pvec(1:(10^y), sqrt, mc.cores=x))[3] 
            )
        })

##           [,1]   [,2]   [,3]   [,4]   [,5]   [,6]
## elapsed  0.079  0.063  0.055  0.058  0.084  0.092
## elapsed  0.334  0.442  0.393  0.350  0.530  0.623
## elapsed  2.159  4.508  3.761  3.456  3.633  3.741
## elapsed 18.562 24.887 39.576 33.213 33.622 34.600
```

## mclapply {.smaller}

Parallelized version of `lapply`

```{r}
system.time(rnorm(1e6))
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 2)))
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 4)))
```

## {.smaller}

```{r}
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 4)))
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 8)))
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 10)))
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 12)))
```

## mcparallel {.smaller}

Asynchronously evaluation of an R expression in a separate process

```{r}
m = mcparallel(rnorm(1e6))
n = mcparallel(rbeta(1e6,1,1))
o = mcparallel(rgamma(1e6,1,1))

str(m)
str(n)
```

## mccollect

Checks `mcparallel` objects for completion

```{r}
str(mccollect(list(m,n,o)))
```

## mccollect - waiting {.smaller}

```{r}
p = mcparallel(mean(rnorm(1e5)))
mccollect(p, wait = FALSE, 10) # will retrieve the result (since it's fast)
mccollect(p, wait = FALSE)     # will signal the job as terminating
mccollect(p, wait = FALSE)     # there is no longer such a job
```

# doMC & foreach

## doMC & foreach

Packages by Revolution Analytics that provides the `foreach` function which is a parallelizable `for` loop (and then some).

* Core functions:
    
    * `registerDoMC`

    * `foreach`, `%dopar%`, `%do%`

## registerDoMC {.smaller}

Primarily used to set the number of cores used by `foreach`, by default uses `options("cores")` or half the number of cores found by `detectCores` from the parallel package.

```{r}
options("cores")
detectCores()
getDoParWorkers()

registerDoMC(4)
getDoParWorkers()
```

## foreach {.smaller}

A slightly more powerful version of base `for` loops (think `for` with an `lapply` flavor). Combined with `%do%` or `%dopar%` for single or multicore execution.

```{r}
for(i in 1:10) sqrt(i)

foreach(i = 1:5) %do% sqrt(i)   
```

## foreach - iterators {.smaller}

`foreach` can iterate across more than one value

<div class="columns-2">
```{r}
foreach(i = 1:5, j = 1:5) %do% sqrt(i^2+j^2)   
```
```{r}
foreach(i = 1:5, j = 1:2) %do% sqrt(i^2+j^2)   
```
<br/><br/><br/><br/>
</div>


## foreach - combining results {.smaller}

```{r}
foreach(i = 1:5, .combine='c') %do% sqrt(i)   
foreach(i = 1:5, .combine='cbind') %do% sqrt(i)   
foreach(i = 1:5, .combine='+') %do% sqrt(i)   
```


## foreach - parallelization {.smaller}

Swapping out `%do%` for `%dopar%` will use the parallel backend.

```{r}
registerDoMC(4)
system.time(foreach(i = 1:10) %dopar% mean(rnorm(1e6)))
registerDoMC(8)
system.time(foreach(i = 1:10) %dopar% mean(rnorm(1e6)))
registerDoMC(12)
system.time(foreach(i = 1:10) %dopar% mean(rnorm(1e6)))
```

# What now?

## What to use when?

Optimal use of multiple cores is hard, there isn't one best solution

* More art than science - experimentation is key

* Measure it or it didn't happen

* Be aware of the trade off between developer time and run time

